####################
#
# Example Job for HTCondor
#
####################

#---------------------------------------------
# Name your batch so it's easy to distinguish in the q.
JobBatchName = "Deepfashion"

# --------------------------------------------
# Executable and its arguments
executable    = $ENV(PWD)/miniconda3/envs/ldm/bin/python
arguments     = $ENV(PWD)/main.py -t --base $ENV(PWD)/configs/deepfashion/highres_condor.yaml --resume $ENV(PWD)/logs/deepfashion_512  --gpus 0, --scale_lr False --num_nodes 1


# ---------------------------------------------------
# Universe (vanilla, docker)
universe         = docker
docker_image     = nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu20.04

# -------------------------------------------------
# Event, out and error logs
log    = c$(cluster).p$(process).log
output = c$(cluster).p$(process).out
error  = c$(cluster).p$(process).error

# -----------------------------------
# File Transfer, Input, Output
should_transfer_files = YES

# Make certain project spaces available in container
environment = "mount=$ENV(PWD),/vol/research/posetoimage/"

# -------------------------------------
# Requirements for the Job (Requirements are explained in further detail in example09.submit_file)
# NOTE: HasStornext is not valid on orca.
requirements = (HasStorenext) && (CUDAGlobalMemoryMb > 20000)  &&  (CUDACapability >= 7.0)

# --------------------------------------
# Resources
request_GPUs     = 1
# this needs to be specified for the AI@Surrey cluster if requesting a GPU
+GPUMem          = 10000  
#request_CPUs     = 48
request_memory   = 64G

#This job will complete in less than 1 hour
+JobRunTime = 4

#This job can checkpoint
+CanCheckpoint = true

# -----------------------------------
# Queue commands
queue
